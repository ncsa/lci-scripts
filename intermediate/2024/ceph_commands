## House keeping (LCI 2024)
# Install following on all clients (lci-head-XX-1, lci-compute-XX-[1-2])
dnf install attr 

# Install lvm2 on all storage nodes (lci-storage-XX-[1-4])
dnf install lvm2 -y

# Copy SSH key from lci-head-XX-1 to lci-storage-XX-1
rsync -avP ~/.ssh/id_rsa lci-storage-XX-1:/root/.ssh/

## From lci-storage-XX-1 do the below:

## Get base ceph installed
export CEPH_RELEASE=18.2.2
curl --silent --remote-name --location https://download.ceph.com/rpm-${CEPH_RELEASE}/el8/noarch/cephadm
chmod +x cephadm
./cephadm add-repo --release reef
./cephadm install

## Push out ceph key from lci-storage-XX-1
ssh-copy-id -f -i /etc/ceph/ceph.pub root@lci-storage-XX-2
ssh-copy-id -f -i /etc/ceph/ceph.pub root@lci-storage-XX-3
ssh-copy-id -f -i /etc/ceph/ceph.pub root@lci-storage-XX-4

## Bootstrap your cluster
cephadm bootstrap --mon-ip $(grep storage /etc/hosts | head -n 1 | awk '{print $1}') --allow-fqdn-hostname
cephadm shell -- ceph -v
cephadm shell -- ceph status

## Expand the cluster
cephadm shell -- ceph orch host add lci-storage-XX-2.novalocal $(grep lci-storage-XX-2 /etc/hosts | awk '{print $1}')
cephadm shell -- ceph orch host add lci-storage-XX-3.novalocal $(grep lci-storage-XX-3 /etc/hosts | awk '{print $1}')
cephadm shell -- ceph orch host add lci-storage-XX-4.novalocal $(grep lci-storage-XX-4 /etc/hosts | awk '{print $1}')

## Verify 4 mon nodes
cephadm shell -- ceph status

## Show all available devices
cephadm shell -- ceph orch device ls

## Add disks to Ceph
cephadm shell -- ceph orch apply osd --all-available-devices
cephadm shell -- ceph status

## Create CephFS
cephadm shell -- ceph fs volume create lci lci-storage-XX-1.novalocal,lci-storage-XX-2.novalocal

## Place Ceph Repo on Compute nodes and head node (following contents in /etc/yum.repos.d/ceph_stable.repo)

[ceph_stable]
baseurl = http://download.ceph.com/rpm-reef/el8/$basearch
gpgcheck = 1
gpgkey = https://download.ceph.com/keys/release.asc
name = Ceph Stable $basearch Repo

## Install Ceph Client on compute nodes and head node
dnf install ceph-common -y

## Make mount point on compute nodes and head node
mkdir /mnt/cephfs

## Gen key on lci-storage-XX-1
cd /etc/ceph
cephadm shell -- ceph auth get-key client.admin > admin.secret

## Sync these files from lci-storage-XX-1 to all clients (lci-compute-XX-[1-2], lci-head-XX-1)
/etc/ceph/admin.secret
/etc/ceph.client.admin.keyring
/etc/ceph.conf

## Mount CephFS on all clients (lci-compute-XX-[1-2], lci-head-XX-1)
mount -t ceph $(grep storage /etc/hosts | awk '{print $1}' | xargs | sed 's/\ /,/g'):/ /mnt/cephfs -o name=admin,secretfile=/etc/ceph/admin.secret

## Sample project directories
cd /mnt/cephfs
mkdir -p projects/A
mkdir -p projects/B
mkdir -p projects/C

## Set Quotas
setfattr -n ceph.quota.max_bytes -v 104857600 /mnt/cephfs/projects/A  # A 100MB quota on dir A
setfattr -n ceph.quota.max_files -v 100000 /mnt/cephfs/projects/B # A 100,000 inode limit on dir B

## Can view quotas with:
getfattr -n ceph.quota.max_bytes /mnt/cephfs/projects/A
getfattr -n ceph.quota.max_files /mnt/cephfs/projects/B
